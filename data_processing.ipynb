{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1163,
   "id": "25c04738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "CVS_PATH = 'student/student-por.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "id": "2ccc0732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       no\n",
      "1       no\n",
      "2       no\n",
      "3      yes\n",
      "4       no\n",
      "      ... \n",
      "644     no\n",
      "645     no\n",
      "646     no\n",
      "647     no\n",
      "648     no\n",
      "Name: romantic, Length: 649, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(CVS_PATH, delimiter=';')\n",
    "print(df['romantic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4778f6d",
   "metadata": {},
   "source": [
    "Now We will define Columns that are nominal (not ordinal) and need one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "id": "a2b98772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLUMNS_TO_CATEGORIZE = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid',\n",
    "                         'activities', 'nursery', 'higher', 'internet', 'romantic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "id": "e1d5c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "644    0\n",
      "645    0\n",
      "646    0\n",
      "647    0\n",
      "648    0\n",
      "Name: romantic_yes, Length: 649, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(\n",
    "    df, \n",
    "    columns=COLUMNS_TO_CATEGORIZE,\n",
    "    prefix=COLUMNS_TO_CATEGORIZE\n",
    ").astype(int)\n",
    "\n",
    "print(df['romantic_yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "id": "c480a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_NORMALIZE = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "5ee6dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[COLUMNS_TO_NORMALIZE] = scaler.fit_transform(df[COLUMNS_TO_NORMALIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "id": "ab0084a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romantic_no', 'romantic_yes']\n",
      "[[ 1.0316951   1.3102156   1.5407155  ...  1.          1.\n",
      "   0.        ]\n",
      " [ 0.21013668 -1.3360394  -1.1888323  ...  1.          0.\n",
      "   1.        ]\n",
      " [-1.4329803  -1.3360394  -1.1888323  ...  1.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 1.0316951  -1.3360394  -1.1888323  ...  1.          1.\n",
      "   0.        ]\n",
      " [ 0.21013668  0.42813063 -1.1888323  ...  1.          0.\n",
      "   1.        ]\n",
      " [ 1.0316951   0.42813063 -0.27898306 ...  1.          0.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print([c for c in df.columns if \"roman\" in c])\n",
    "X = df.drop(columns=['G3', 'romantic_yes', 'romantic_no']).values.astype(np.float32)\n",
    "y_grade = df['G3'].values.astype(np.float32).reshape(-1, 1)  \n",
    "y_romantic = df['romantic_yes'].values.astype(int)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "id": "7c065f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_grade_trainval, y_grade_test, y_rom_trainval, y_rom_test = train_test_split(\n",
    "    X, y_grade, y_romantic, test_size=0.15, random_state=42\n",
    ")\n",
    "X_train, X_val, y_grade_train, y_grade_val, y_rom_train, y_rom_val = train_test_split(\n",
    "    X_trainval, y_grade_trainval, y_rom_trainval, test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "id": "857e3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StudentDatasetPor(Dataset):\n",
    "    def __init__(self, X, y_grade, y_romantic):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y_grade = torch.tensor(y_grade, dtype=torch.float32)\n",
    "        self.y_romantic = torch.tensor(y_romantic, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_grade[idx], self.y_romantic[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "id": "8fa8cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StudentDatasetPor(X_train, y_grade_train, y_rom_train)\n",
    "val_dataset = StudentDatasetPor(X_val, y_grade_val, y_rom_val)\n",
    "test_dataset = StudentDatasetPor(X_test, y_grade_test, y_rom_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "id": "4b1bed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "FIRST_NEURON_N = 64\n",
    "SECOND_NEURON_N = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "id": "a093324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, FIRST_NEURON_N),\n",
    "            nn.BatchNorm1d(FIRST_NEURON_N),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(FIRST_NEURON_N, SECOND_NEURON_N),\n",
    "            nn.BatchNorm1d(SECOND_NEURON_N),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.grade_head = nn.Linear(SECOND_NEURON_N, 1)\n",
    "        \n",
    "        self.romantic_head = nn.Linear(SECOND_NEURON_N, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.shared(x)\n",
    "\n",
    "        grade_pred = self.grade_head(features)\n",
    "        romantic_logit = self.romantic_head(features)\n",
    "\n",
    "        return grade_pred, romantic_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "id": "90e706d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "id": "5a823264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = StudentMLP(X.shape[1]).to(device)\n",
    "\n",
    "class_counts = np.bincount(y_romantic)\n",
    "class_weights = torch.FloatTensor([1.0/class_counts[0], 1.0/class_counts[1]]).to(device)\n",
    "\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "criterion_grade = nn.MSELoss()               \n",
    "criterion_romantic = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "id": "d10bbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.8849\n",
      "Epoch [2/50], Train Loss: 1.2673\n",
      "Epoch [3/50], Train Loss: 1.1398\n",
      "Epoch [4/50], Train Loss: 1.0279\n",
      "Epoch [5/50], Train Loss: 1.0195\n",
      "Epoch [6/50], Train Loss: 0.9759\n",
      "Epoch [7/50], Train Loss: 0.9426\n",
      "Epoch [8/50], Train Loss: 0.9474\n",
      "Epoch [9/50], Train Loss: 0.8914\n",
      "Epoch [10/50], Train Loss: 0.8939\n",
      "Epoch [11/50], Train Loss: 0.9020\n",
      "Epoch [12/50], Train Loss: 0.9008\n",
      "Epoch [13/50], Train Loss: 0.8432\n",
      "Epoch [14/50], Train Loss: 0.8654\n",
      "Epoch [15/50], Train Loss: 0.9052\n",
      "Epoch [16/50], Train Loss: 0.8532\n",
      "Epoch [17/50], Train Loss: 0.7958\n",
      "Epoch [18/50], Train Loss: 0.8227\n",
      "Epoch [19/50], Train Loss: 0.8486\n",
      "Epoch [20/50], Train Loss: 0.8196\n",
      "Epoch [21/50], Train Loss: 0.8271\n",
      "Epoch [22/50], Train Loss: 0.7775\n",
      "Epoch [23/50], Train Loss: 0.7955\n",
      "Epoch [24/50], Train Loss: 0.7774\n",
      "Epoch [25/50], Train Loss: 0.7602\n",
      "Epoch [26/50], Train Loss: 0.7514\n",
      "Epoch [27/50], Train Loss: 0.7772\n",
      "Epoch [28/50], Train Loss: 0.7828\n",
      "Epoch [29/50], Train Loss: 0.7314\n",
      "Epoch [30/50], Train Loss: 0.7516\n",
      "Epoch [31/50], Train Loss: 0.7519\n",
      "Epoch [32/50], Train Loss: 0.6821\n",
      "Epoch [33/50], Train Loss: 0.7000\n",
      "Epoch [34/50], Train Loss: 0.7290\n",
      "Epoch [35/50], Train Loss: 0.6667\n",
      "Epoch [36/50], Train Loss: 0.7187\n",
      "Epoch [37/50], Train Loss: 0.7071\n",
      "Epoch [38/50], Train Loss: 0.7271\n",
      "Epoch [39/50], Train Loss: 0.6880\n",
      "Epoch [40/50], Train Loss: 0.6734\n",
      "Epoch [41/50], Train Loss: 0.6607\n",
      "Epoch [42/50], Train Loss: 0.6184\n",
      "Epoch [43/50], Train Loss: 0.7160\n",
      "Epoch [44/50], Train Loss: 0.6628\n",
      "Epoch [45/50], Train Loss: 0.6294\n",
      "Epoch [46/50], Train Loss: 0.6681\n",
      "Epoch [47/50], Train Loss: 0.6028\n",
      "Epoch [48/50], Train Loss: 0.6693\n",
      "Epoch [49/50], Train Loss: 0.6437\n",
      "Epoch [50/50], Train Loss: 0.6221\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x_batch, y_grade_batch, y_romantic_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_grade_batch = y_grade_batch.to(device)\n",
    "        y_rom_batch = y_romantic_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        grade_pred, romantic_logits = model(x_batch)\n",
    "\n",
    "        loss_grade = criterion_grade(grade_pred, y_grade_batch)\n",
    "        loss_romantic = criterion_romantic(romantic_logits, y_romantic_batch)\n",
    "\n",
    "        loss = loss_grade + loss_romantic\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    total_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Train Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "id": "68e57cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_loss_grade = 0\n",
    "    total_loss_romantic = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_grade_batch, y_rom_batch in data_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_grade_batch = y_grade_batch.to(device)\n",
    "            y_rom_batch = y_rom_batch.to(device)\n",
    "            \n",
    "            grade_pred, romantic_logits = model(x_batch)\n",
    "            \n",
    "            loss_grade = criterion_grade(grade_pred, y_grade_batch)\n",
    "            loss_romantic = criterion_romantic(romantic_logits, y_rom_batch)\n",
    "            loss = loss_grade + loss_romantic\n",
    "            \n",
    "            total_loss += loss.item() * x_batch.size(0)\n",
    "            total_loss_grade += loss_grade.item() * x_batch.size(0)\n",
    "            total_loss_romantic += loss_romantic.item() * x_batch.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "    avg_loss_grade = total_loss_grade / len(data_loader.dataset)\n",
    "    avg_loss_romantic = total_loss_romantic / len(data_loader.dataset)\n",
    "    \n",
    "    return {\n",
    "        'total_loss': avg_loss,\n",
    "        'grade_loss': avg_loss_grade,\n",
    "        'romantic_loss': avg_loss_romantic,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "id": "04dc96da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_loss': 1.0301241242741963, 'grade_loss': 0.1882410246026085, 'romantic_loss': 0.8418830949139883}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model=model, data_loader=val_loader, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb54105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_grade_preds = []\n",
    "    all_grade_true = []\n",
    "\n",
    "    all_romantic_preds = []\n",
    "    all_romantic_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_grade_batch, y_romantic_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_grade_batch = y_grade_batch.to(device)\n",
    "            y_romantic_batch = y_romantic_batch.to(device)\n",
    "\n",
    "            grade_out, romantic_out = model(x_batch)\n",
    "\n",
    "            all_grade_preds.extend(grade_out.cpu().numpy().flatten())\n",
    "            all_grade_true.extend(y_grade_batch.cpu().numpy().flatten())\n",
    "\n",
    "            romantic_pred_labels = romantic_out.argmax(dim=1)\n",
    "            all_romantic_preds.extend(romantic_pred_labels.cpu().numpy())\n",
    "            all_romantic_true.extend(y_romantic_batch.cpu().numpy())\n",
    "\n",
    "\n",
    "    mae = mean_absolute_error(all_grade_true, all_grade_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_romantic_true, all_romantic_preds)\n",
    "\n",
    "    f1_yes = f1_score(all_romantic_true, all_romantic_preds, pos_label=1)\n",
    "\n",
    "    return {\n",
    "        \"grade_MAE\": mae,\n",
    "        \"romantic_accuracy\": accuracy,\n",
    "        \"romantic_f1_yes\": f1_yes\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "5c0e6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grade_MAE': 0.2845036464420204, 'romantic_accuracy': 0.5408163265306123, 'romantic_f1_yes': 0.3835616438356164}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_test(model=model, test_loader=test_loader, device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
